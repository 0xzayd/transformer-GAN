{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Discriminator import Discriminator\n",
    "from models.Generator import Generator\n",
    "\n",
    "from src.utils import objectview\n",
    "\n",
    "from src.functions import train, validate, LinearLrDecay, load_params, copy_params, cur_stages\n",
    "from src.utils import set_log_dir, save_checkpoint, create_logger\n",
    "from src.metrics.inception_score import _init_inception\n",
    "from src.metrics.fid_score import create_inception_graph, check_or_download_inception\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from adamw import AdamW\n",
    "\n",
    "import datasets\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'init_type':'normal',\n",
    "    'mask':8_8,\n",
    "    'gf_dim':1024,\n",
    "    'df_dim':,\n",
    "    'latent_dim':1024,\n",
    "    'd_depth':5,\n",
    "    'patch_size':1,\n",
    "    'img_size':32,\n",
    "    'diff_aug':'translation',\n",
    "    'optimizer': 'adamw',\n",
    "    'lr_G':1e-5,\n",
    "    'lr_D':1e-5,\n",
    "    'wd':1e-3,\n",
    "    'beta1':0,\n",
    "    'beta2':0.99,\n",
    "    'max_iter':100000,\n",
    "    'max_epoch':200,\n",
    "    'output_dir':'ckpt',\n",
    "    'n_critic':5,\n",
    "    'dataset':'cifar10',\n",
    "    'data_path':'.',\n",
    "    'num_workers':36,\n",
    "    'dis_batch_size':100,\n",
    "    'fad_in':0\n",
    "}\n",
    "\n",
    "options=objectview(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator(options)\n",
    "netG = Discriminator(options)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        if options.init_type == 'normal':\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif options.init_type == 'orth':\n",
    "            nn.init.orthogonal_(m.weight.data)\n",
    "        elif options.init_type == 'xavier_uniform':\n",
    "            nn.init.xavier_uniform(m.weight.data, 1.)\n",
    "        else:\n",
    "            raise NotImplementedError('{} unknown inital type'.format(options.init_type))\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "gpu_ids = [i for i in range(int(torch.cuda.device_count()))]\n",
    "netG = torch.nn.DataParallel(netG.to(\"cuda:0\"), device_ids=gpu_ids)\n",
    "netD = torch.nn.DataParallel(netD.to(\"cuda:0\"), device_ids=gpu_ids)\n",
    "\n",
    "if options.optimizer == \"adam\":\n",
    "    optimizerG = torch.optim.Adam(filter(lambda p: p.requires_grad, netG.parameters()),\n",
    "                                    options.lr_G, (options.beta1, options.beta2))\n",
    "    optimizerD = torch.optim.Adam(filter(lambda p: p.requires_grad, netD.parameters()),\n",
    "                                    options.lr_D, (options.beta1, options.beta2))\n",
    "elif options.optimizer == \"adamw\":\n",
    "    optimizerG = AdamW(filter(lambda p: p.requires_grad, netG.parameters()),\n",
    "                                    options.lr_G, weight_decay=options.wd)\n",
    "    optimizerD = AdamW(filter(lambda p: p.requires_grad, netD.parameters()),\n",
    "                                     options.lr_D, weight_decay=options.wd)\n",
    "    \n",
    "schedulerG= LinearLrDecay(gen_optimizer, options.lr_G, 0.0, 0, options.max_iter * options.n_critic)\n",
    "schedulerD = LinearLrDecay(dis_optimizer, options.lr_D, 0.0, 0, options.max_iter * options.n_critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageDataset(options, cur_img_size=8)\n",
    "train_loader = dataset.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(options.max_epoch):\n",
    "        train(options, gen_net = netG, dis_net = netD, gen_optimizer = optimizerG, dis_optimizer = optimizerD, gen_avg_param = None, train_loader = train_loader,\n",
    "            epoch = epoch, writer_dict = writer_dict, fixed_z = None, schedulers=[schedulerG, schedulerD])\n",
    "\n",
    "        checkpoint = {'epoch':epoch, 'best_fid':best}\n",
    "        checkpoint['gen_state_dict'] = gen_net.state_dict()\n",
    "        checkpoint['dis_state_dict'] = dis_net.state_dict()\n",
    "        score = validate(options, None, fid_stat, epoch, gen_net, writer_dict, clean_dir=True)\n",
    "        # print these scores, is it really the latest\n",
    "        print(f'FID score: {score} - best ID score: {best} || @ epoch {epoch}.')\n",
    "        if epoch == 0 or epoch > 30:\n",
    "            if score < best:\n",
    "                save_checkpoint(checkpoint, is_best=(score<best), output_dir=options.output_dir)\n",
    "                print(\"Saved Latest Model!\")\n",
    "                best = score\n",
    "\n",
    "    checkpoint = {'epoch':epoch, 'best_fid':best}\n",
    "    checkpoint['gen_state_dict'] = gen_net.state_dict()\n",
    "    checkpoint['dis_state_dict'] = dis_net.state_dict()\n",
    "    score = validate(options, None, fid_stat, epoch, gen_net, writer_dict, clean_dir=True)\n",
    "    save_checkpoint(checkpoint, is_best=(score<best), output_dir=options.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
